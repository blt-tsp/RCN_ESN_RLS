{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwbQUXtHAjDv"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHzl7e6rXnNk"
      },
      "outputs": [],
      "source": [
        "#%pip install pycuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03ERFp6lFWIe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import struct\n",
        "import random\n",
        "#import pycuda\n",
        "#import pycuda.autoinit\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import Ridge\n",
        "#from pycuda.tools import make_default_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqEicl4rFaPz"
      },
      "outputs": [],
      "source": [
        "PATH = \"drive/MyDrive/data_pfe\"\n",
        "#PATH = \"drive/MyDrive/TSP/3A/PFE/data\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE-byEtWYDNb"
      },
      "source": [
        "## Preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzQnyW58XzLf"
      },
      "outputs": [],
      "source": [
        "with open(os.path.join(PATH, 'train-images.idx3-ubyte'),'rb') as f:\n",
        "    magic, size = struct.unpack(\">II\", f.read(8))\n",
        "    nrows, ncols = struct.unpack(\">II\", f.read(8))\n",
        "    train_images = np.fromfile(f, dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
        "    train_images = train_images.reshape((size, nrows, ncols))\n",
        "f.close()\n",
        "\n",
        "with open(os.path.join(PATH, 'train-labels.idx1-ubyte'),'rb') as f:\n",
        "    magic, size = struct.unpack(\">II\", f.read(8))\n",
        "    train_labels = np.fromfile(f, dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
        "    train_labels = train_labels.reshape((size,))\n",
        "f.close()\n",
        "\n",
        "with open(os.path.join(PATH, 't10k-images.idx3-ubyte'),'rb') as f:\n",
        "    magic, size = struct.unpack(\">II\", f.read(8))\n",
        "    nrows, ncols = struct.unpack(\">II\", f.read(8))\n",
        "    test_images = np.fromfile(f, dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
        "    test_images = test_images.reshape((size, nrows, ncols))\n",
        "f.close()\n",
        "\n",
        "with open(os.path.join(PATH, 't10k-labels.idx1-ubyte'),'rb') as f:\n",
        "    magic, size = struct.unpack(\">II\", f.read(8))\n",
        "    test_labels = np.fromfile(f, dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
        "    test_labels = test_labels.reshape((size,))\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2d8JaT4EYWcQ"
      },
      "outputs": [],
      "source": [
        "print(\"Shape of the training images set : \", np.shape(train_images))\n",
        "print(\"Shape of the training labels set : \", np.shape(train_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilMD3FPSUIaL"
      },
      "outputs": [],
      "source": [
        "plt.imshow(train_images[25], cmap='Greys')\n",
        "plt.show()\n",
        "print(\"Label of the example image : \", train_labels[25])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwjfnJRu_n48"
      },
      "outputs": [],
      "source": [
        "# Normalizing the data\n",
        "\n",
        "train_images = (train_images - np.mean(train_images)) / np.std(train_images)\n",
        "test_images = (test_images - np.mean(test_images)) / np.std(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Rux6bYoXmP9"
      },
      "outputs": [],
      "source": [
        "def images_to_TS(images, labels) : \n",
        "\n",
        "  n_images, img_size, _ = np.shape(images)\n",
        "  T = n_images * img_size\n",
        "  U = np.zeros((T, img_size))\n",
        "  V = np.zeros((T, 10))\n",
        "\n",
        "  for i in range(n_images) : \n",
        "    U[i*img_size : (i+1)*img_size] = images[i]\n",
        "    for j in range(img_size) : \n",
        "      V[i*img_size + j][labels[i]] = 1\n",
        "\n",
        "  return U, V\n",
        "\n",
        "U_train, V_train = images_to_TS(train_images, train_labels)\n",
        "U_test, V_test = images_to_TS(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hi2SQfXvZrOc"
      },
      "outputs": [],
      "source": [
        "# Random shuffle\n",
        "\n",
        "#idx_train = np.random.permutation(np.shape(U_train)[0])\n",
        "#U_train, V_train = U_train[idx_train], V_train[idx_train]\n",
        "#idx_test = np.random.permutation(np.shape(U_test)[0])\n",
        "#U_test, V_test = U_test[idx_test], V_test[idx_test]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_cwML8F-4h_"
      },
      "outputs": [],
      "source": [
        "print(\"Shape of the training set : \\t\\t\", np.shape(U_train))\n",
        "print(\"Shape of the training labels set : \\t\", np.shape(V_train))\n",
        "print(\"Shape of the test set : \\t\\t\", np.shape(U_test))\n",
        "print(\"Shape of the test labels set : \\t\\t\", np.shape(V_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WmdxyEkYO9O"
      },
      "source": [
        "## Create the ESN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y78_xv2fFhhX"
      },
      "source": [
        "Notations : \n",
        "- **n_inputs** : number of input nodes (same as the image size)\n",
        "- **n_reservoir** : number of neurons in the reservoir\n",
        "- **n_outputs** : number of readouts (10 in our case)\n",
        "- **W_in** : input weights of shape (Nx, Nu)\n",
        "- **W** : reservoir weights of shape (Nx, Nx)\n",
        "- **W_back** : return weights of shape (Nx, Ny)\n",
        "- **W_out** : output weights of shape (Ny, Nx)\n",
        "- **U** : training set of shape (T, Nu) where T is the length of the times series\n",
        "- **V** : set of training labels of shape (T, Ny) where the labels are one-hot encoded\n",
        "- **X** : reservoir states of shape (Nx, T)\n",
        "- **Y** : labels corresponding to the reservoir states (Ny, T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byA7m6bvFiZh"
      },
      "outputs": [],
      "source": [
        "img_size = 28\n",
        "Nu = img_size     # size of the input signal\n",
        "Nx = 500           # number of neurons in the reservoir\n",
        "Ny = 10           # number of readouts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gs3GEfmAGYzo"
      },
      "outputs": [],
      "source": [
        "class ESN_2():\n",
        "\n",
        "  def param_init_random(self) : \n",
        "\n",
        "    self.x_0 = np.zeros(self.Nx)\n",
        "    self.y_0 = np.zeros(self.Ny)\n",
        "\n",
        "    self.W_in = np.empty((self.Nx, self.Nu))\n",
        "    self.W = np.empty((self.Nx, self.Nx))\n",
        "    self.W_back = np.empty((self.Nx, self.Ny))\n",
        "    self.W_bias = np.zeros(self.Nx)\n",
        "\n",
        "    for i in range(self.Nx) : \n",
        "      for j in range(self.Nu) : \n",
        "        w = np.random.rand()\n",
        "        if w < 0.2 : \n",
        "          self.W_in[i,j] = -1\n",
        "        elif w >= 0.2 and w < 0.4 : \n",
        "          self.W_in[i,j] = 1\n",
        "        else : \n",
        "          self.W_in[i,j] = 0\n",
        "      for j in range(self.Nx) : \n",
        "        if i>=j : \n",
        "          self.W[i,j] = np.exp(-i / 240)\n",
        "      for j in range(self.Ny) : \n",
        "        w = np.random.rand()\n",
        "        if w < 0.2 : \n",
        "          self.W_back[i,j] = -1\n",
        "        elif w >= 0.2 and w < 0.4 : \n",
        "          self.W_back[i,j] = 1\n",
        "        else : \n",
        "          self.W_back[i,j] = 0\n",
        "      self.W_bias[i] = np.random.rand()\n",
        "    \n",
        "    return self.W_in, self.W, self.W_back, self.W_bias\n",
        "\n",
        "  def forward(self, s, alpha) : \n",
        "        return (1 - alpha) * np.tanh(s)\n",
        "\n",
        "  def compute_reservoir_states(self, U, V) : \n",
        "\n",
        "    T = np.shape(U)[0]\n",
        "    X = np.array([self.x_0]).T\n",
        "    Y = np.array([self.y_0]).T\n",
        "\n",
        "    for t in range(1, T+1) : \n",
        "      s = self.W_in @ U[t-1] + self.W @ X[:, t-1] + self.W_back @ Y[:, t-1] + self.W_bias\n",
        "      x_t = self.forward(s, self.alpha) \n",
        "      x_t.shape = (np.shape(x_t)[0], 1)\n",
        "      X = np.hstack([X, x_t])\n",
        "      Y = np.hstack([Y, np.reshape(V[t-1], (np.shape(V[t-1])[0], 1))])\n",
        "\n",
        "    return X[:, 1:], Y[:, 1:]\n",
        "\n",
        "  def compute_W_out(self, X, Y, alpha=1.0) : \n",
        "    clf = Ridge(alpha=alpha, fit_intercept=False)\n",
        "    clf.fit(X.T, Y.T)\n",
        "    r2 = clf.score(X.T, Y.T)\n",
        "    self.W_out = clf.coef_\n",
        "    return r2\n",
        "\n",
        "\n",
        "  def predict(self, U_test, X, Y) : \n",
        "    \n",
        "    n_samples = np.shape(U_test)[0]\n",
        "    T = np.shape(X)[1]\n",
        "    \n",
        "    for i in range(1, n_samples + 1) : \n",
        "      s = self.W_in @ U_test[i-1] + self.W @ X[:, T+i-2] + self.W_back @ Y[:, T+i-2] + self.W_bias\n",
        "      x_i = self.forward(s, self.alpha)\n",
        "      x_i.shape = (np.shape(x_i)[0], 1)\n",
        "      X = np.hstack([X, x_i])\n",
        "\n",
        "      \n",
        "      # Compute output\n",
        "      y_i = self.W_out @ x_i\n",
        "      y_i.shape = (np.shape(y_i)[0], 1)\n",
        "      Y = np.hstack([Y, y_i])\n",
        "    \n",
        "    column_preds = Y[:, T:].T\n",
        "    preds = []\n",
        "\n",
        "    n_images = n_samples // self.Nu\n",
        "    for j in range(n_images) : \n",
        "      column_labels = np.argmax(column_preds[j*self.Nu : (j+1)*self.Nu], axis=1)\n",
        "      label = np.argmax(np.bincount(column_labels))\n",
        "      preds.append(label)\n",
        "    \n",
        "    return np.array(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GQ0UvJ-dNJx"
      },
      "outputs": [],
      "source": [
        "def identity(x):\n",
        "    return x\n",
        "\n",
        "def tanh(x) : \n",
        "  return np.tanh(x)\n",
        "\n",
        "def forward(self, s, alpha) : \n",
        "    return (1 - alpha) * np.tanh(s)\n",
        "\n",
        "def correct_dimensions(s, targetlength):   # https://github.com/cknd/pyESN/blob/master/pyESN.py\n",
        "    \"\"\"checks the dimensionality of some numeric argument s, broadcasts it\n",
        "       to the specified length if possible.\n",
        "    Args:\n",
        "        s: None, scalar or 1D array\n",
        "        targetlength: expected length of s\n",
        "    Returns:\n",
        "        None if s is None, else numpy vector of length targetlength\n",
        "    \"\"\"\n",
        "    if s is not None:\n",
        "        s = np.array(s)\n",
        "        if s.ndim == 0:\n",
        "            s = np.array([s] * targetlength)\n",
        "        elif s.ndim == 1:\n",
        "            if not len(s) == targetlength:\n",
        "                raise ValueError(\"arg must have length \" + str(targetlength))\n",
        "        else:\n",
        "            raise ValueError(\"Invalid argument\")\n",
        "    return s\n",
        "\n",
        "class ESN() : \n",
        "\n",
        "  def __init__(self, n_inputs, n_outputs, \n",
        "               n_reservoir=32, alpha=0.99, spectral_radius=1.5, sparsity=0, noise=0.001,\n",
        "               input_scaling=None, input_shift=None, \n",
        "               teacher_forcing=True, teacher_scaling=None, teacher_shift=None,\n",
        "               feedback_scaling=None, \n",
        "               out_activation=identity, inverse_out_activation=identity,\n",
        "               random_state=None, \n",
        "               use_gradient_descent=False, learning_rate=0.01, l2_rate=10e-5) :\n",
        "    \n",
        "    # spectral radius = spectral radius of W_rec\n",
        "    # sparsity = proportion of recurrent weights set to zero\n",
        "    # noise = noise added to each neuron (regularization)\n",
        "    # random_state = positive seed\n",
        "    # input_shift: scalar or vector of length n_inputs to add to each input dimension before feeding it to the network.\n",
        "    # input_scaling: scalar or vector of length n_inputs to multiply with each input dimension before feeding it to the netw.\n",
        "    # teacher_forcing: if True, feed the target back into output units\n",
        "    # teacher_scaling: factor applied to the target signal\n",
        "    # teacher_shift: additive term applied to the target signal\n",
        "    # out_activation: output activation function (applied to the readout)\n",
        "    # inverse_out_activation: inverse of the output activation function\n",
        "\n",
        "    self.n_inputs = n_inputs\n",
        "    self.n_outputs = n_outputs\n",
        "    self.n_reservoir = n_reservoir\n",
        "     \n",
        "    self.noise = noise\n",
        "    self.spectral_radius = spectral_radius\n",
        "    self.alpha = alpha\n",
        "\n",
        "    self.random_state = random_state\n",
        "    self.sparsity = sparsity\n",
        "\n",
        "    self.teacher_forcing = teacher_forcing\n",
        "    self.teacher_scaling = teacher_scaling\n",
        "    self.teacher_shift = teacher_shift\n",
        "    self.feedback_scaling = feedback_scaling\n",
        "    self.input_shift = correct_dimensions(input_shift, n_inputs)\n",
        "    self.input_scaling = correct_dimensions(input_scaling, n_inputs)\n",
        "    \n",
        "    self.out_activation = identity\n",
        "    self.inverse_out_activation = identity \n",
        "\n",
        "    if isinstance(random_state, np.random.RandomState):\n",
        "        self.random_state_ = random_state\n",
        "    elif random_state:\n",
        "        try:\n",
        "            self.random_state_ = np.random.RandomState(random_state)\n",
        "        except TypeError as e:\n",
        "            raise Exception(\"Invalid seed: \" + str(e))\n",
        "    else:\n",
        "        self.random_state_ = np.random.mtrand._rand\n",
        "    \n",
        "    self.init_weights()\n",
        "\n",
        "    self.use_gradient_descent = use_gradient_descent\n",
        "    self.learning_rate = learning_rate\n",
        "    self.l2_rate = l2_rate\n",
        "\n",
        "  def init_weights(self) : \n",
        "\n",
        "    self.x_0 = np.zeros(self.n_inputs)\n",
        "    self.y_0 = np.zeros(self.n_outputs)\n",
        "\n",
        "    self.W_in = np.empty((self.n_reservoir, self.n_inputs))\n",
        "    self.W = np.empty((self.n_reservoir, self.n_reservoir))\n",
        "    self.W_back = np.empty((self.n_reservoir, self.n_outputs))\n",
        "    self.W_bias = np.zeros(self.n_reservoir)\n",
        "  \n",
        "    # initialize recurrent weights:\n",
        "    # begin with a random matrix centered around zero:\n",
        "    W = self.random_state_.rand(self.n_reservoir, self.n_reservoir) - 0.5\n",
        "\n",
        "    # delete the fraction of connections given by (self.sparsity):\n",
        "    W[self.random_state_.rand(*W.shape) < self.sparsity] = 0\n",
        "    \n",
        "    # compute the spectral radius of these weights:\n",
        "    radius = np.max(np.abs(np.linalg.eigvals(W)))\n",
        "\n",
        "    # rescale them to reach the requested spectral radius:\n",
        "    self.W_rec = W * (self.spectral_radius / radius)\n",
        "    \n",
        "    # random input weights:\n",
        "    self.W_in = self.random_state_.rand(\n",
        "        self.n_reservoir, self.n_inputs) * 2 - 1\n",
        "    \n",
        "    # random feedback (teacher forcing) weights:\n",
        "    self.W_back = self.random_state_.rand(\n",
        "        self.n_reservoir, self.n_outputs) * 2 - 1\n",
        "  \n",
        "  def one_step(self, state, input, output):\n",
        "\n",
        "    if self.teacher_forcing :\n",
        "      preact = np.dot(self.W_rec, state) + np.dot(self.W_in, input) + np.dot(self.W_back, output) \n",
        "    else :\n",
        "      preact = np.dot(self.W_rec, state) + np.dot(self.W_in, input)\n",
        "    \n",
        "    return forward(self, preact, self.alpha) + self.noise * (self.random_state_.rand(self.n_reservoir) - 0.5)\n",
        "\n",
        "  def _scale_inputs(self, inputs):\n",
        "    \"\"\"for each input dimension j: multiplies by the j'th entry in the\n",
        "    input_scaling argument, then adds the j'th entry of the input_shift\n",
        "    argument.\"\"\"\n",
        "    if self.input_scaling is not None:\n",
        "      inputs = np.dot(inputs, np.diag(self.input_scaling))\n",
        "    if self.input_shift is not None:\n",
        "      inputs = inputs + self.input_shift\n",
        "    return inputs\n",
        "\n",
        "  def _scale_teacher(self, teacher):\n",
        "    \"\"\"multiplies the teacher/target signal by the teacher_scaling argument,\n",
        "    then adds the teacher_shift argument to it.\"\"\"\n",
        "    if self.teacher_scaling is not None:\n",
        "      teacher = teacher * self.teacher_scaling\n",
        "    if self.teacher_shift is not None:\n",
        "      teacher = teacher + self.teacher_shift\n",
        "    return teacher\n",
        "\n",
        "  def _unscale_teacher(self, teacher_scaled):\n",
        "    \"\"\"inverse operation of the _scale_teacher method.\"\"\"\n",
        "    if self.teacher_shift is not None:\n",
        "      teacher_scaled = teacher_scaled - self.teacher_shift\n",
        "    if self.teacher_scaling is not None:\n",
        "      teacher_scaled = teacher_scaled / self.teacher_scaling\n",
        "    return teacher_scaled\n",
        "\n",
        "  def fit(self, inputs, outputs, inspect=False):\n",
        "    if inputs.ndim < 2:\n",
        "      inputs = np.reshape(inputs, (len(inputs), -1))\n",
        "    if outputs.ndim < 2:\n",
        "      outputs = np.reshape(outputs, (len(outputs), -1))\n",
        "    # transform input and teacher signal:\n",
        "    inputs_scaled = self._scale_inputs(inputs)\n",
        "    teachers_scaled = self._scale_teacher(outputs)\n",
        "\n",
        "    if self.use_gradient_descent : \n",
        "      self.W_out = self.random_state_.rand(self.n_outputs, self.n_reservoir+self.n_inputs) * 2 - 1\n",
        "\n",
        "    states = np.zeros((inputs.shape[0], self.n_reservoir))\n",
        "\n",
        "    print(\"computing states ...\")\n",
        "    for n in range(1, inputs.shape[0]):\n",
        "      states[n, :] = self.one_step(states[n-1, :], inputs_scaled[n-1, :], teachers_scaled[n-1, :])\n",
        "      if self.use_gradient_descent : \n",
        "        extended = np.hstack((states[n,:], inputs_scaled[n,:]))\n",
        "        self.W_out = self.W_out*(1 - self.learning_rate*self.l2_rate)\n",
        "        self.W_out += self.learning_rate * np.reshape((teachers_scaled[n,:] - self.W_out@extended), (self.n_outputs, 1)) @ np.reshape(extended, (self.n_reservoir+self.n_inputs, 1)).T\n",
        "\n",
        "    if not self.use_gradient_descent : \n",
        "      # including inputs \n",
        "      extended = np.hstack((states, inputs_scaled))\n",
        "\n",
        "      #calculing W_out \n",
        "      print(\"computing W_out ...\")\n",
        "      self.W_out = np.dot(np.linalg.pinv(extended), \n",
        "                            self.inverse_out_activation(teachers_scaled)).T\n",
        "\n",
        "    self.laststate = states[-1,:]\n",
        "    self.lastinput = inputs[-1,:]\n",
        "    self.lastoutput = outputs[-1,:]\n",
        "\n",
        "    print(\"Training error ...\")\n",
        "    pred_train = self._unscale_teacher(self.out_activation(\n",
        "        np.dot( extended, self.W_out.T)))\n",
        "    print(np.sqrt(np.mean((pred_train - outputs)**2)))\n",
        "    return pred_train\n",
        "\n",
        "  def score(self, u, v):\n",
        "    return np.sqrt(np.mean((u - v)**2))\n",
        "\n",
        "  def predict(self, inputs, continuation=True):\n",
        "    # if continuation = True, start the RcNN from the last training state\n",
        "\n",
        "    n_samples = inputs.shape[0]\n",
        "\n",
        "    if continuation == True : \n",
        "      laststate = self.laststate \n",
        "      lastinput = self.lastinput\n",
        "      lastoutput = self.lastoutput \n",
        "    \n",
        "    else :\n",
        "      laststate = np.zeros(self.n_reservoir)\n",
        "      lastinput = np.zeros(self.n_inputs)\n",
        "      lastoutput = np.zeros(self.n_outputs)\n",
        "\n",
        "    inputs = np.vstack([lastinput, self._scale_inputs(inputs)])\n",
        "    states = np.vstack([laststate, np.zeros((n_samples, self.n_reservoir))])\n",
        "    outputs = np.vstack([lastoutput, np.zeros((n_samples, self.n_outputs))])\n",
        "\n",
        "    for n in range(n_samples): \n",
        "      states[n+1, :] = self.one_step(states[n, :], inputs[n+1, :], outputs[n, :])\n",
        "      outputs[n+1, :] = self.out_activation(np.dot(self.W_out, np.concatenate([states[n+1, :], inputs[n+1, :]])))\n",
        "\n",
        "    #return self._unscale_teacher(self.out_activation(outputs[1,:]))\n",
        "\n",
        "    column_preds = self._unscale_teacher(self.out_activation(outputs[1:, :]))\n",
        "    preds = []\n",
        "\n",
        "    n_images = n_samples // self.n_inputs\n",
        "    for j in range(n_images) : \n",
        "      column_labels = np.argmax(column_preds[j*self.n_inputs : (j+1)*self.n_inputs], axis=1)\n",
        "      label = np.argmax(np.bincount(column_labels))\n",
        "      preds.append(label)\n",
        "    \n",
        "    return np.array(preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOVx7eSpFF7V"
      },
      "source": [
        "## Test the ESN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzEa-D7tTmUo"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "esn = ESN(n_inputs = 28, n_outputs = 10, n_reservoir = 100,\n",
        "          alpha = 0.9, spectral_radius = 0.25, sparsity = 0.95, noise = 0.001)\n",
        "\n",
        "esn.fit(U_train, V_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqZ4eFarnyVm"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "preds = esn.predict(U_test[:5600], continuation=True)\n",
        "print(\"Accuracy : \", accuracy_score(test_labels[:200], preds[:200]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmlO5vOghFfp"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "esn = ESN(n_inputs = 28, n_outputs = 10, n_reservoir = 400,\n",
        "          alpha = 0.001, spectral_radius = 1, sparsity = 0.5, noise = 0.001, input_scaling=0.1, \n",
        "          input_shift=0.05, teacher_scaling=0.001, teacher_shift=0.1, teacher_forcing=False, feedback_scaling=0.2, \n",
        "          out_activation=identity, inverse_out_activation=identity, \n",
        "          use_gradient_descent=True)\n",
        "\n",
        "train_preds = esn.fit(U_train[:60000], V_train[:60000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zy771KhoU5DM"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "preds = esn.predict(U_test[:10000], continuation=True)\n",
        "print(\"Accuracy : \", accuracy_score(test_labels[:300], preds[:300]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = [10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000]\n",
        "y = [0.64, 0.697, 0.763, 0.777, 0.813, 0.797, 0.787, 0.787]\n",
        "plt.plot(x, y, color= 'r', marker = '+')\n",
        "plt.grid()\n",
        "plt.xlabel('Number of training samples')\n",
        "plt.ylabel('Test accuracy')"
      ],
      "metadata": {
        "id": "n8lxyH9cHniF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = [107, 105, 144, 184, 230, 277, 334, 401]\n",
        "plt.plot(x, z, color = 'r', marker = '+')\n",
        "plt.grid()\n",
        "plt.xlabel('Number of training samples')\n",
        "plt.ylabel('Training time (s)')"
      ],
      "metadata": {
        "id": "p6C9yS7mH5Mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = [100, 200, 300, 400, 500, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
        "y = [0.3865, 0.447, 0.5055, 0.5615, 0.57, 0.606, 0.661, 0.6895, 0.7155, 0.7105, 0.7375, 0.752, 0.763]\n",
        "plt.plot(x, y, color = 'r', marker = '+')\n",
        "plt.grid()\n",
        "plt.xlabel('Number of reservoir neurons')\n",
        "plt.ylabel('Test accuracy')"
      ],
      "metadata": {
        "id": "-nZ04slX7uNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = [13.6, 18.7, 25.5, 38.4, 33.1, 46.6, 68, 111, 127, 165, 209, 270, 374]\n",
        "plt.plot(x, z, color = 'r', marker = '+')\n",
        "plt.grid()\n",
        "plt.xlabel('Number of reservoir neurons')\n",
        "plt.ylabel('Training time (s)')"
      ],
      "metadata": {
        "id": "J8Wc7DHgHHrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ejl112JTnKt"
      },
      "source": [
        "## Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ka_lBRdUcg0e"
      },
      "outputs": [],
      "source": [
        "class ESNEstimator() : \n",
        "\n",
        "  def __init__(self, n_inputs, n_outputs, \n",
        "               n_reservoir=32, alpha=0.99, spectral_radius=1.5, sparsity=0, \n",
        "               noise=0.001, input_scaling=None, input_shift=None, \n",
        "               teacher_forcing=True, teacher_scaling=None, teacher_shift=None,\n",
        "               feedback_scaling=None, \n",
        "               out_activation=identity, inverse_out_activation=identity,\n",
        "               random_state = None, \n",
        "               use_gradient_descent=False, learning_rate=0.01, l2_rate=10e-5) :\n",
        "    \n",
        "    # spectral radius = spectral radius of W_rec\n",
        "    # sparsity = proportion of recurrent weights set to zero\n",
        "    # noise = noise added to each neuron (regularization)\n",
        "    # random_state = positive seed\n",
        "    # input_shift: scalar or vector of length n_inputs to add to each input dimension before feeding it to the network.\n",
        "    # input_scaling: scalar or vector of length n_inputs to multiply with each input dimension before feeding it to the netw.\n",
        "    # teacher_forcing: if True, feed the target back into output units\n",
        "    # teacher_scaling: factor applied to the target signal\n",
        "    # teacher_shift: additive term applied to the target signal\n",
        "    # out_activation: output activation function (applied to the readout)\n",
        "    # inverse_out_activation: inverse of the output activation function\n",
        "    \n",
        "    self.n_inputs = n_inputs\n",
        "    self.n_outputs = n_outputs\n",
        "    self.n_reservoir = n_reservoir\n",
        "     \n",
        "    self.noise = noise\n",
        "    self.spectral_radius = spectral_radius\n",
        "    self.alpha = alpha\n",
        "\n",
        "    self.random_state = random_state\n",
        "    self.sparsity = sparsity\n",
        "\n",
        "    self.teacher_forcing = teacher_forcing\n",
        "    self.teacher_scaling = teacher_scaling\n",
        "    self.teacher_shift = teacher_shift\n",
        "    self.feedback_scaling = feedback_scaling\n",
        "    self.input_shift = input_shift\n",
        "    self.input_scaling = input_scaling\n",
        "    \n",
        "    self.out_activation = identity\n",
        "    self.inverse_out_activation = identity \n",
        "\n",
        "    if isinstance(self.random_state, np.random.RandomState):\n",
        "        self.random_state_ = self.random_state\n",
        "    elif random_state:\n",
        "        try:\n",
        "            self.random_state_ = np.random.RandomState(self.random_state)\n",
        "        except TypeError as e:\n",
        "            raise Exception(\"Invalid seed: \" + str(e))\n",
        "    else:\n",
        "        self.random_state_ = np.random.mtrand._rand\n",
        "    \n",
        "    self.use_gradient_descent = use_gradient_descent\n",
        "    self.learning_rate = learning_rate\n",
        "    self.l2_rate = l2_rate\n",
        "\n",
        "    #self.init_weights()\n",
        "\n",
        "  def get_params(self, deep=True):\n",
        "        # Return the hyperparameters as a dictionary\n",
        "        return {'n_inputs': self.n_inputs, 'n_outputs': self.n_outputs, 'n_reservoir': self.n_reservoir, \n",
        "                'alpha': self.alpha, 'spectral_radius': self.spectral_radius, 'sparsity': self.sparsity, \n",
        "                'noise': self.noise, 'input_scaling': self.input_scaling, \n",
        "                'input_shift': self.input_shift, 'teacher_forcing': self.teacher_forcing, \n",
        "                'teacher_scaling': self.teacher_scaling, 'teacher_shift': self.teacher_shift, \n",
        "                'feedback_scaling': self.feedback_scaling, 'out_activation': self.out_activation, \n",
        "                'inverse_out_activation': self.inverse_out_activation, 'random_state': self.random_state, \n",
        "                'use_gradient_descent': self.use_gradient_descent, 'learning_rate': self.learning_rate, 'l2_rate': self.l2_rate}\n",
        "\n",
        "  def set_params(self, **params):\n",
        "        # Set the hyperparameters\n",
        "\n",
        "        self.n_reservoir = params['n_reservoir']\n",
        "        self.alpha = params['alpha']\n",
        "        self.spectral_radius = params['spectral_radius']\n",
        "        self.sparsity = params['sparsity']\n",
        "        self.noise = params['noise']\n",
        "        self.input_scaling = params['input_scaling']\n",
        "        self.input_shift = params['input_scaling']\n",
        "        self.teacher_forcing = params['teacher_forcing']\n",
        "        self.teacher_scaling = params['teacher_scaling']\n",
        "        self.teacher_shift = params['teacher_shift']\n",
        "        self.feedback_scaling = params['feedback_scaling']\n",
        "        self.out_activation = params['out_activation']\n",
        "        self.inverse_out_activation = params['inverse_out_activation']\n",
        "        self.random_state = params['random_state']\n",
        "        self.use_gradient_descent = params['use_gradient_descent']\n",
        "        self.learning_rate = params['learning_rate']\n",
        "        self.l2_rate = params['l2_rate']\n",
        "        return self\n",
        "\n",
        "  def init_weights(self) : \n",
        "\n",
        "    self.x_0 = np.zeros(self.n_inputs)\n",
        "    self.y_0 = np.zeros(self.n_outputs)\n",
        "\n",
        "    self.W_in = np.empty((self.n_reservoir, self.n_inputs))\n",
        "    self.W = np.empty((self.n_reservoir, self.n_reservoir))\n",
        "    self.W_back = np.empty((self.n_reservoir, self.n_outputs))\n",
        "    self.W_bias = np.zeros(self.n_reservoir)\n",
        "  \n",
        "    # initialize recurrent weights:\n",
        "    # begin with a random matrix centered around zero:\n",
        "    W = self.random_state_.rand(self.n_reservoir, self.n_reservoir) - 0.5\n",
        "\n",
        "    # delete the fraction of connections given by (self.sparsity):\n",
        "    W[self.random_state_.rand(*W.shape) < self.sparsity] = 0\n",
        "    \n",
        "    # compute the spectral radius of these weights:\n",
        "    radius = np.max(np.abs(np.linalg.eigvals(W)))\n",
        "\n",
        "    # rescale them to reach the requested spectral radius:\n",
        "    self.W_rec = W * (self.spectral_radius / radius)\n",
        "    \n",
        "    # random input weights:\n",
        "    self.W_in = self.random_state_.rand(\n",
        "        self.n_reservoir, self.n_inputs) * 2 - 1\n",
        "    \n",
        "    # random feedback (teacher forcing) weights:\n",
        "    self.W_back = self.random_state_.rand(\n",
        "        self.n_reservoir, self.n_outputs) * 2 - 1\n",
        "  \n",
        "  def one_step(self, state, input, output):\n",
        "\n",
        "    if self.teacher_forcing :\n",
        "      preact = np.dot(self.W_rec, state) + np.dot(self.W_in, input) + np.dot(self.W_back, output) \n",
        "    \n",
        "    else :\n",
        "      preact = np.dot(self.W_rec, state) + np.dot(self.W_in, input)\n",
        "    \n",
        "    return forward(self, preact, self.alpha) + self.noise * (self.random_state_.rand(self.n_reservoir) - 0.5)\n",
        "\n",
        "  def _scale_inputs(self, inputs):\n",
        "    \"\"\"for each input dimension j: multiplies by the j'th entry in the\n",
        "    input_scaling argument, then adds the j'th entry of the input_shift\n",
        "    argument.\"\"\"\n",
        "    if self.input_scaling is not None:\n",
        "      inputs = np.dot(inputs, np.diag(self.input_scaling))\n",
        "    if self.input_shift is not None:\n",
        "      inputs = inputs + self.input_shift\n",
        "    return inputs\n",
        "\n",
        "  def _scale_teacher(self, teacher):\n",
        "    \"\"\"multiplies the teacher/target signal by the teacher_scaling argument,\n",
        "    then adds the teacher_shift argument to it.\"\"\"\n",
        "    if self.teacher_scaling is not None:\n",
        "      teacher = teacher * self.teacher_scaling\n",
        "    if self.teacher_shift is not None:\n",
        "      teacher = teacher + self.teacher_shift\n",
        "    return teacher\n",
        "\n",
        "  def _unscale_teacher(self, teacher_scaled):\n",
        "    \"\"\"inverse operation of the _scale_teacher method.\"\"\"\n",
        "    if self.teacher_shift is not None:\n",
        "      teacher_scaled = teacher_scaled - self.teacher_shift\n",
        "    if self.teacher_scaling is not None:\n",
        "      teacher_scaled = teacher_scaled / self.teacher_scaling\n",
        "    return teacher_scaled\n",
        "\n",
        "  def fit(self, inputs, outputs, inspect=False):\n",
        "\n",
        "    self.init_weights()\n",
        "    self.input_shift = correct_dimensions(self.input_shift, self.n_inputs)\n",
        "    self.input_scaling = correct_dimensions(self.input_scaling, self.n_inputs)\n",
        "\n",
        "    if inputs.ndim < 2:\n",
        "      inputs = np.reshape(inputs, (len(inputs), -1))\n",
        "    if outputs.ndim < 2:\n",
        "      outputs = np.reshape(outputs, (len(outputs), -1))\n",
        "    # transform input and teacher signal:\n",
        "    inputs_scaled = self._scale_inputs(inputs)\n",
        "    teachers_scaled = self._scale_teacher(outputs)\n",
        "\n",
        "    if self.use_gradient_descent : \n",
        "      self.W_out = self.random_state_.rand(self.n_outputs, self.n_reservoir+self.n_inputs) * 2 - 1\n",
        "\n",
        "    states = np.zeros((inputs.shape[0], self.n_reservoir))\n",
        "\n",
        "    for n in range(1, inputs.shape[0]):\n",
        "      states[n, :] = self.one_step(states[n-1, :], inputs_scaled[n-1, :], teachers_scaled[n-1, :])\n",
        "      if self.use_gradient_descent : \n",
        "        extended = np.hstack((states[n,:], inputs_scaled[n,:]))\n",
        "        self.W_out = self.W_out*(1 - self.learning_rate*self.l2_rate)\n",
        "        self.W_out += self.learning_rate * np.reshape((teachers_scaled[n,:] - self.W_out@extended), (self.n_outputs, 1)) @ np.reshape(extended, (self.n_reservoir+self.n_inputs, 1)).T\n",
        "\n",
        "    if not self.use_gradient_descent : \n",
        "      # including inputs \n",
        "      extended = np.hstack((states, inputs_scaled))\n",
        "\n",
        "      #calculing W_out \n",
        "      self.W_out = np.dot(np.linalg.pinv(extended), \n",
        "                          self.inverse_out_activation(teachers_scaled)).T\n",
        "\n",
        "    self.laststate = states[-1,:]\n",
        "    self.lastinput = inputs[-1,:]\n",
        "    self.lastoutput = outputs[-1,:]\n",
        "\n",
        "    print(\"Training error ...\")\n",
        "    pred_train = self._unscale_teacher(self.out_activation(\n",
        "        np.dot( extended, self.W_out.T)))\n",
        "    print(np.sqrt(np.mean((pred_train - outputs)**2)))\n",
        "    return pred_train\n",
        "\n",
        "  def score(self, u, v):\n",
        "    return np.sqrt(np.mean((u - v)**2))\n",
        "\n",
        "  def predict(self, inputs, continuation=True):\n",
        "    # if continuation = True, start the RcNN from the last training state\n",
        "\n",
        "    n_samples = inputs.shape[0]\n",
        "\n",
        "    if continuation == True : \n",
        "      laststate = self.laststate \n",
        "      lastinput = self.lastinput\n",
        "      lastoutput = self.lastoutput \n",
        "    \n",
        "    else :\n",
        "      laststate = np.zeros(self.n_reservoir)\n",
        "      lastinput = np.zeros(self.n_inputs)\n",
        "      lastoutput = np.zeros(self.n_outputs)\n",
        "\n",
        "    inputs = np.vstack([lastinput, self._scale_inputs(inputs)])\n",
        "    states = np.vstack([laststate, np.zeros((n_samples, self.n_reservoir))])\n",
        "    outputs = np.vstack([lastoutput, np.zeros((n_samples, self.n_outputs))])\n",
        "\n",
        "    for n in range(n_samples): \n",
        "      states[n+1, :] = self.one_step(states[n, :], inputs[n+1, :], outputs[n, :])\n",
        "      outputs[n+1, :] = self.out_activation(np.dot(self.W_out, np.concatenate([states[n+1, :], inputs[n+1, :]])))\n",
        "\n",
        "    return self._unscale_teacher(self.out_activation(outputs[1,:]))\n",
        "\n",
        "    \"\"\"column_preds = self._unscale_teacher(self.out_activation(outputs[1:, :]))\n",
        "    preds = []\n",
        "\n",
        "    n_images = n_samples // self.n_inputs\n",
        "    for j in range(n_images) : \n",
        "      column_labels = np.argmax(column_preds[j*self.n_inputs : (j+1)*self.n_inputs], axis=1)\n",
        "      label = np.argmax(np.bincount(column_labels))\n",
        "      preds.append(label)\n",
        "    \n",
        "    return np.array(preds)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Y9sLr7Nsu4G"
      },
      "outputs": [],
      "source": [
        "# GridSearch\n",
        "%%time\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "esn = ESN(n_inputs=28, n_outputs=10)\n",
        "scoring_func = make_scorer(esn.score)\n",
        "\n",
        "param_grid = {'n_reservoir': [300],       # peut être fixé (300 ou 400)\n",
        "          'alpha': [0.001],           # peut être fixé\n",
        "          'spectral_radius': [1], \n",
        "          'sparsity': [0.5], \n",
        "          'noise': [0.001], \n",
        "          'input_scaling': [0.1],        # à affiner\n",
        "          'input_shift': [0.05], \n",
        "          'teacher_forcing': [True], \n",
        "          'teacher_scaling': [0.001], \n",
        "          'teacher_shift': [0.2], \n",
        "          'feedback_scaling': [0.01],     # à affiner\n",
        "          'out_activation': [identity], \n",
        "          'inverse_out_activation': [identity], \n",
        "          'random_state': [None], \n",
        "          'use_gradient_descent': [True], \n",
        "          'learning_rate': [0.00001, 0.0001, 0.001], \n",
        "          'l2_rate': [0.0000001, 0.000001, 0.00001]}\n",
        "\n",
        "gs = GridSearchCV(ESNEstimator(n_inputs=28, n_outputs=10), param_grid=param_grid, scoring=scoring_func)\n",
        "gs.fit(U_train[:30000], V_train[:30000])\n",
        "\n",
        "results = pd.DataFrame(gs.cv_results_).drop(columns=[\"param_inverse_out_activation\", \"param_out_activation\", \"params\", \"split0_test_score\", \"split1_test_score\", \"split2_test_score\", \"split3_test_score\", \"split4_test_score\", \"mean_fit_time\", \"std_fit_time\", \"mean_score_time\", \"std_score_time\"])\n",
        "results = results.sort_values(by=\"rank_test_score\")\n",
        "print(results.head(5))\n",
        "print(\"Best score : \", gs.best_score_)\n",
        "print(\"Best params : \\n\", gs.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKH8zOeVA_XN"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "best_esn = ESN(n_inputs = 28, n_outputs = 10, \n",
        "                        n_reservoir = gs.best_params_['n_reservoir'], \n",
        "                        alpha = gs.best_params_['alpha'], \n",
        "                        spectral_radius = gs.best_params_['spectral_radius'], \n",
        "                        sparsity = gs.best_params_['sparsity'], \n",
        "                        noise = gs.best_params_['noise'], \n",
        "                        input_scaling = gs.best_params_['input_scaling'], \n",
        "                        input_shift = gs.best_params_['input_shift'], \n",
        "                        teacher_forcing = gs.best_params_['teacher_forcing'], \n",
        "                        teacher_scaling = gs.best_params_['teacher_scaling'], \n",
        "                        teacher_shift = gs.best_params_['teacher_shift'], \n",
        "                        feedback_scaling = gs.best_params_['feedback_scaling'], \n",
        "                        out_activation = gs.best_params_['out_activation'], \n",
        "                        inverse_out_activation = gs.best_params_['inverse_out_activation'], \n",
        "                        random_state = gs.best_params_['random_state'], \n",
        "                        use_gradient_descent = gs.best_params_['use_gradient_descent'], \n",
        "                        learning_rate = gs.best_params_['learning_rate'], \n",
        "                        l2_rate = gs.best_params_['l2_rate']\n",
        ")\n",
        "\n",
        "train_preds = best_esn.fit(U_train[:60000], V_train[:60000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4IUSVcwA_Rn"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "preds = best_esn.predict(U_test[:30000], continuation=True)\n",
        "print(\"Accuracy : \", accuracy_score(test_labels[:1000], preds[:1000]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOjp4MWz2PwQ"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "With params\n",
        "  {'alpha': 0.8, 'feedback_scaling': 0.9, 'input_scaling': 0.4, 'input_shift': 0.1, 'inverse_out_activation': <function identity at 0x7fc233f234c0>, \n",
        "  'n_reservoir': 200, 'noise': 0.001, 'out_activation': <function identity at 0x7fc233f234c0>, 'random_state': None, 'sparsity': 0.5, 'spectral_radius': 0.8, \n",
        "  'teacher_forcing': True, 'teacher_scaling': 0.1, 'teacher_shift': None}\n",
        "we obtain the following accuracy on the test set : \n",
        "  0.28\n",
        "\n",
        "With params\n",
        "  {'alpha': 0.9, 'feedback_scaling': 0.6, 'input_scaling': 0.6, 'input_shift': 0.1, 'inverse_out_activation': <function identity at 0x7f0b2ef60040>, \n",
        "  'n_reservoir': 200, 'noise': 0.001, 'out_activation': <function identity at 0x7f0b2ef60040>, 'random_state': None, 'sparsity': 0.5, 'spectral_radius': 0.8, \n",
        "  'teacher_forcing': False, 'teacher_scaling': None, 'teacher_shift': 0.1}\n",
        "we obtain the following accuracy on the test set : \n",
        "  0.343\n",
        "\n",
        "With params\n",
        " {'alpha': 0.5, 'feedback_scaling': 0.6, 'input_scaling': 0.6, 'input_shift': 0.1, 'inverse_out_activation': <function identity at 0x7f0b2ef60040>, \n",
        " 'n_reservoir': 200, 'noise': 0.001, 'out_activation': <function identity at 0x7f0b2ef60040>, 'random_state': None, 'sparsity': 0.5, 'spectral_radius': 1, \n",
        " 'teacher_forcing': False, 'teacher_scaling': None, 'teacher_shift': 0.1}\n",
        "we obtain the following accuracy on the test set : \n",
        "  0.406\n",
        "\n",
        "With params\n",
        " {'alpha': 0.4, 'feedback_scaling': 0.6, 'input_scaling': 0.6, 'input_shift': 0.1, 'inverse_out_activation': <function identity at 0x7f0b2ef60040>, \n",
        " 'n_reservoir': 200, 'noise': 0.001, 'out_activation': <function identity at 0x7f0b2ef60040>, 'random_state': None, 'sparsity': 0.5, 'spectral_radius': 0.8, \n",
        " 'teacher_forcing': False, 'teacher_scaling': None, 'teacher_shift': 0.1}\n",
        "we obtain the following accuracy on the test set : \n",
        "  0.428\n",
        "\n",
        "With params\n",
        " {'alpha': 0.3, 'feedback_scaling': 0.6, 'input_scaling': 0.6, 'input_shift': 0.2, 'inverse_out_activation': <function identity at 0x7f0b2ef60040>, \n",
        " 'n_reservoir': 200, 'noise': 0.001, 'out_activation': <function identity at 0x7f0b2ef60040>, 'random_state': None, 'sparsity': 0.5, 'spectral_radius': 1, \n",
        " 'teacher_forcing': False, 'teacher_scaling': None, 'teacher_shift': 0.4}\n",
        "we obtain the following accuracy on the test set : \n",
        "  0.45\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras"
      ],
      "metadata": {
        "id": "3EWewwZSKpli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34m5BW3u2PuQ"
      },
      "outputs": [],
      "source": [
        "#random search \n",
        "%%time \n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV  \n",
        "from scipy.stats import uniform, norm\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "esn = ESNEstimator(n_inputs=28, n_outputs=10)\n",
        "scoring_func = make_scorer(esn.score)\n",
        "\n",
        "distrib = dict(n_reservoir = [2500], \n",
        "               alpha = norm(0.00001, 0.01), \n",
        "               spectral_radius = [0.4, 0.6, 0.8, 1], \n",
        "               sparsity = [0.5], \n",
        "               noise = [0.001],  \n",
        "               input_scaling = norm(0.1, 0.01), \n",
        "               input_shift = norm(0.05, 0.005), \n",
        "               teacher_scaling = norm(0.01, 0.001), \n",
        "               teacher_shift = norm(0.2, 0.02), \n",
        "               teacher_forcing = [True], \n",
        "               random_state = [None], \n",
        "               feedback_scaling = norm(0.01, 0.001),\n",
        "               out_activation = [identity],  \n",
        "               inverse_out_activation = [identity], \n",
        "               use_gradient_descent = [True],\n",
        "               learning_rate = norm(0.001, 0.0001), \n",
        "               l2_rate = norm(0.001, 0.0001))\n",
        "\n",
        "clf = RandomizedSearchCV(esn, distrib, random_state=0, scoring=scoring_func)\n",
        "\n",
        "search = clf.fit(U_train[:30000], V_train[:30000])\n",
        "search.best_params_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0QnxLn02PrR"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "best_esn = ESN(n_inputs = 28, n_outputs = 10, \n",
        "                n_reservoir = search.best_params_['n_reservoir'],\n",
        "                alpha = search.best_params_['alpha'], \n",
        "                spectral_radius = search.best_params_['spectral_radius'], \n",
        "                sparsity = search.best_params_['sparsity'], \n",
        "                noise = search.best_params_['noise'], \n",
        "                input_scaling = search.best_params_['input_scaling'], \n",
        "                input_shift = search.best_params_['input_shift'], \n",
        "                teacher_forcing = search.best_params_['teacher_forcing'], \n",
        "                teacher_scaling = search.best_params_['teacher_scaling'], \n",
        "                teacher_shift = search.best_params_['teacher_shift'], \n",
        "                feedback_scaling = search.best_params_['feedback_scaling'], \n",
        "                out_activation = search.best_params_['out_activation'], \n",
        "                inverse_out_activation = search.best_params_['inverse_out_activation'], \n",
        "                random_state = search.best_params_['random_state'], \n",
        "                use_gradient_descent = search.best_params_['use_gradient_descent'], \n",
        "                learning_rate = search.best_params_['learning_rate'], \n",
        "                l2_rate = search.best_params_['l2_rate']\n",
        ")\n",
        "               \n",
        "train_preds = best_esn.fit(U_train[:30000], V_train[:30000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOJmjeXs2PpF"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "preds = best_esn.predict(U_test[:60000], continuation=True)\n",
        "print(\"Accuracy : \", accuracy_score(test_labels[:1000], preds[:1000]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"# RCN_ESN_RLS\" >> README.md\n",
        "!git init\n",
        "!git add README.md\n",
        "!git commit -m \"first commit\"\n",
        "!git branch -M main\n",
        "!git remote add origin https://github.com/blt-tsp/RCN_ESN_RLS.git\n",
        "!git push -u origin main"
      ],
      "metadata": {
        "id": "EnapJYpIG4QG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TLw9L6p7G4Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HGMVNgUFG4IB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XmAXmuxcG4Fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFWkX3fWBHRr"
      },
      "source": [
        "## ESN avec GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPQpts_Q8mdU"
      },
      "outputs": [],
      "source": [
        "import pycuda.driver as cuda\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "def matmul_gpu(a, b) : \n",
        "\n",
        "  n, m = np.shape(a)\n",
        "  m_, p = np.shape(b)\n",
        "  if m != m_ : \n",
        "    raise ValueError(\"Invalid arguments\")\n",
        "  n = np.int32(n)\n",
        "  m = np.int32(m)\n",
        "  p = np.int32(p)\n",
        "\n",
        "  c = np.zeros((n, p), dtype=np.float32)\n",
        "\n",
        "  a_gpu = cuda.mem_alloc(a.size * a.dtype.itemsize)\n",
        "  b_gpu = cuda.mem_alloc(b.size * b.dtype.itemsize)\n",
        "  c_gpu = cuda.mem_alloc(c.size * c.dtype.itemsize)\n",
        "\n",
        "  cuda.memcpy_htod(a_gpu, a)\n",
        "  cuda.memcpy_htod(b_gpu, b)\n",
        "\n",
        "  mod = SourceModule(\"\"\"\n",
        "    __global__ void multiply\n",
        "    ( int n, int m, int p,\n",
        "    float *a, float *b, float *c )\n",
        "    {\n",
        "    int idx = p*threadIdx.x + threadIdx.y;\n",
        "    c[idx] = 0.0;\n",
        "    for(int k=0; k<m; k++)\n",
        "    c[idx] += a[m*threadIdx.x+k]\n",
        "    *b[threadIdx.y+k*p];\n",
        "    }\n",
        "    \"\"\")\n",
        "  \n",
        "  func = mod.get_function(\"multiply\")\n",
        "  func(n, m, p, a_gpu, b_gpu, c_gpu, block=(int(n), int(p), 1), grid=(1, 1), shared=0)\n",
        "  cuda.memcpy_dtoh(c, c_gpu)\n",
        "  return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6bawcnVBQIE"
      },
      "outputs": [],
      "source": [
        "class ESN_gpu() : \n",
        "\n",
        "  def __init__(self, n_inputs, n_outputs, \n",
        "               n_reservoir=32, alpha=0.99, spectral_radius=1.5, sparsity=0, noise=0.001,\n",
        "               input_scaling=None, input_shift=None, \n",
        "               teacher_forcing=True, teacher_scaling=None, teacher_shift=None,\n",
        "               feedback_scaling=None, \n",
        "               out_activation=identity, inverse_out_activation=identity,\n",
        "               random_state = None) :\n",
        "    \n",
        "    # spectral radius = spectral radius of W_rec\n",
        "    # sparsity = proportion of recurrent weights set to zero\n",
        "    # noise = noise added to each neuron (regularization)\n",
        "    # random_state = positive seed\n",
        "    # input_shift: scalar or vector of length n_inputs to add to each input dimension before feeding it to the network.\n",
        "    # input_scaling: scalar or vector of length n_inputs to multiply with each input dimension before feeding it to the netw.\n",
        "    # teacher_forcing: if True, feed the target back into output units\n",
        "    # teacher_scaling: factor applied to the target signal\n",
        "    # teacher_shift: additive term applied to the target signal\n",
        "    # out_activation: output activation function (applied to the readout)\n",
        "    # inverse_out_activation: inverse of the output activation function\n",
        "\n",
        "    self.n_inputs = n_inputs\n",
        "    self.n_outputs = n_outputs\n",
        "    self.n_reservoir = n_reservoir\n",
        "     \n",
        "    self.noise = noise\n",
        "    self.spectral_radius = spectral_radius\n",
        "    self.alpha = alpha\n",
        "\n",
        "    self.random_state = random_state\n",
        "    self.sparsity = sparsity\n",
        "\n",
        "    self.teacher_forcing = teacher_forcing\n",
        "    self.teacher_scaling = teacher_scaling\n",
        "    self.teacher_shift = teacher_shift\n",
        "    self.feedback_scaling = feedback_scaling\n",
        "    self.input_shift = correct_dimensions(input_shift, n_inputs)\n",
        "    self.input_scaling = correct_dimensions(input_scaling, n_inputs)\n",
        "    \n",
        "    self.out_activation = identity\n",
        "    self.inverse_out_activation = identity \n",
        "\n",
        "    if isinstance(random_state, np.random.RandomState):\n",
        "        self.random_state_ = random_state\n",
        "    elif random_state:\n",
        "        try:\n",
        "            self.random_state_ = np.random.RandomState(random_state)\n",
        "        except TypeError as e:\n",
        "            raise Exception(\"Invalid seed: \" + str(e))\n",
        "    else:\n",
        "        self.random_state_ = np.random.mtrand._rand\n",
        "    \n",
        "    self.init_weights()\n",
        "\n",
        "  def get_params(self, deep=True):\n",
        "        # Return the hyperparameters as a dictionary\n",
        "        return {'n_inputs': self.n_inputs, 'n_outputs': self.n_outputs, 'n_reservoir': self.n_reservoir, 'alpha': self.alpha, \n",
        "                'spectral_radius': self.spectral_radius, 'sparsity': self.sparsity, 'noise': self.noise, \n",
        "                'input_scaling': self.input_scaling, 'input_shift': self.input_shift, 'teacher_forcing': self.teacher_forcing, \n",
        "                'teacher_scaling': self.teacher_scaling, 'teacher_shift': self.teacher_shift, \n",
        "                'feedback_scaling': self.feedback_scaling, 'out_activation': self.out_activation, \n",
        "                'inverse_out_activation': self.inverse_out_activation, 'random_state': self.random_state}\n",
        "\n",
        "  def set_params(self, **params):\n",
        "        # Set the hyperparameters\n",
        "        self.n_inputs = params['n_inputs']\n",
        "        self.n_outputs = params['n_outputs']\n",
        "        self.n_reservoir = params['n_reservoir']\n",
        "        self.alpha = params['alpha']\n",
        "        self.spectral_radius = params['spectral_radius']\n",
        "        self.sparsity = params['sparsity']\n",
        "        self.noise = params['noise']\n",
        "        self.input_scaling = params['input_scaling']\n",
        "        self.input_shift = params['input_scaling']\n",
        "        self.teacher_forcing = params['teacher_forcing']\n",
        "        self.teacher_scaling = params['teacher_forcing']\n",
        "        self.teacher_shift = params['teacher_shift']\n",
        "        self.feedback_scaling = params['feedback_scaling']\n",
        "        self.out_activation = params['out_activation']\n",
        "        self.inverse_out_activation = params['inverse_out_activation']\n",
        "        self.random_state = params['random_state']\n",
        "        return self\n",
        "\n",
        "  def init_weights(self) : \n",
        "\n",
        "    self.x_0 = np.zeros(self.n_inputs)\n",
        "    self.y_0 = np.zeros(self.n_outputs)\n",
        "\n",
        "    self.W_in = np.empty((self.n_reservoir, self.n_inputs))\n",
        "    self.W = np.empty((self.n_reservoir, self.n_reservoir))\n",
        "    self.W_back = np.empty((self.n_reservoir, self.n_outputs))\n",
        "    self.W_bias = np.zeros(self.n_reservoir)\n",
        "  \n",
        "    # initialize recurrent weights:\n",
        "    # begin with a random matrix centered around zero:\n",
        "    W = self.random_state_.rand(self.n_reservoir, self.n_reservoir) - 0.5\n",
        "\n",
        "    # delete the fraction of connections given by (self.sparsity):\n",
        "    W[self.random_state_.rand(*W.shape) < self.sparsity] = 0\n",
        "    \n",
        "    # compute the spectral radius of these weights:\n",
        "    radius = np.max(np.abs(np.linalg.eigvals(W)))\n",
        "\n",
        "    # rescale them to reach the requested spectral radius:\n",
        "    self.W_rec = W * (self.spectral_radius / radius)\n",
        "    \n",
        "    # random input weights:\n",
        "    self.W_in = self.random_state_.rand(\n",
        "        self.n_reservoir, self.n_inputs) * 2 - 1\n",
        "    \n",
        "    # random feedback (teacher forcing) weights:\n",
        "    self.W_back = self.random_state_.rand(\n",
        "        self.n_reservoir, self.n_outputs) * 2 - 1\n",
        "  \n",
        "  def one_step(self, state, input, output):\n",
        "\n",
        "    if self.teacher_forcing :\n",
        "      state.shape = (np.shape(state)[0], 1)\n",
        "      input.shape = (np.shape(input)[0], 1)\n",
        "      output.shape = (np.shape(output)[0], 1)\n",
        "      preact = matmul_gpu(self.W_rec, state) + matmul_gpu(self.W_in, input) + matmul_gpu(self.W_back, output) \n",
        "    else :\n",
        "      state.shape = (np.shape(state)[0], 1)\n",
        "      input.shape = (np.shape(input)[0], 1)\n",
        "      preact = matmul_gpu(self.W_rec, state) + matmul_gpu(self.W_in, input)\n",
        "    preact.shape = (np.shape(preact)[0],)\n",
        "    \n",
        "    return forward(self, preact, self.alpha) + self.noise * (self.random_state_.rand(self.n_reservoir) - 0.5)\n",
        "\n",
        "  def _scale_inputs(self, inputs):\n",
        "    \"\"\"for each input dimension j: multiplies by the j'th entry in the\n",
        "    input_scaling argument, then adds the j'th entry of the input_shift\n",
        "    argument.\"\"\"\n",
        "    if self.input_scaling is not None:\n",
        "      inputs = np.dot(inputs, np.diag(self.input_scaling))\n",
        "    if self.input_shift is not None:\n",
        "      inputs = inputs + self.input_shift\n",
        "    return inputs\n",
        "\n",
        "  def _scale_teacher(self, teacher):\n",
        "    \"\"\"multiplies the teacher/target signal by the teacher_scaling argument,\n",
        "    then adds the teacher_shift argument to it.\"\"\"\n",
        "    if self.teacher_scaling is not None:\n",
        "      teacher = teacher * self.teacher_scaling\n",
        "    if self.teacher_shift is not None:\n",
        "      teacher = teacher + self.teacher_shift\n",
        "    return teacher\n",
        "\n",
        "  def _unscale_teacher(self, teacher_scaled):\n",
        "    \"\"\"inverse operation of the _scale_teacher method.\"\"\"\n",
        "    if self.teacher_shift is not None:\n",
        "      teacher_scaled = teacher_scaled - self.teacher_shift\n",
        "    if self.teacher_scaling is not None:\n",
        "      teacher_scaled = teacher_scaled / self.teacher_scaling\n",
        "    return teacher_scaled\n",
        "\n",
        "  def fit(self, inputs, outputs, inspect=False):\n",
        "    if inputs.ndim < 2:\n",
        "      inputs = np.reshape(inputs, (len(inputs), -1))\n",
        "    if outputs.ndim < 2:\n",
        "      outputs = np.reshape(outputs, (len(outputs), -1))\n",
        "    # transform input and teacher signal:\n",
        "    inputs_scaled = self._scale_inputs(inputs)\n",
        "    teachers_scaled = self._scale_teacher(outputs)\n",
        "\n",
        "    states = np.zeros((inputs.shape[0], self.n_reservoir))\n",
        "\n",
        "    print(\"computing states ...\")\n",
        "    for n in range(1, inputs.shape[0]):\n",
        "      states[n, :] = self.one_step(states[n-1, :], inputs_scaled[n-1, :], teachers_scaled[n-1, :])\n",
        "\n",
        "    # including inputs \n",
        "    extended = np.hstack((states, inputs_scaled))\n",
        "\n",
        "    #calculing W_out \n",
        "    print(\"computing W_out ...\")\n",
        "    print(np.shape(np.linalg.pinv(extended)))\n",
        "    print(\"ok\")\n",
        "    self.W_out = matmul_gpu(np.linalg.pinv(extended), \n",
        "                        self.inverse_out_activation(teachers_scaled)).T\n",
        "    print(\"ok\")\n",
        "\n",
        "    self.laststate = states[-1,:]\n",
        "    self.lastinput = inputs[-1,:]\n",
        "    self.lastoutput = outputs[-1,:]\n",
        "\n",
        "    print(\"Training error ...\")\n",
        "    pred_train = self._unscale_teacher(self.out_activation(\n",
        "        matmul_gpu( extended, self.W_out.T)))\n",
        "    print(np.sqrt(np.mean((pred_train - outputs)**2)))\n",
        "    return pred_train\n",
        "\n",
        "  def score(self, u, v):\n",
        "    return np.sqrt(np.mean((u - v)**2))\n",
        "\n",
        "  def predict(self, inputs, continuation=True):\n",
        "    # if continuation = True, start the RcNN from the last training state\n",
        "\n",
        "    n_samples = inputs.shape[0]\n",
        "\n",
        "    if continuation == True : \n",
        "      laststate = self.laststate \n",
        "      lastinput = self.lastinput\n",
        "      lastoutputt = self.lastoutput \n",
        "    \n",
        "    else :\n",
        "      laststate = np.zeros(self.n_reservoir)\n",
        "      lastinput = np.zeros(self.n_inputs)\n",
        "      lastoutput = np.zeros(self.n_outputs)\n",
        "\n",
        "    inputs = np.vstack([lastinput, self._scale_inputs(inputs)])\n",
        "    states = np.vstack([laststate, np.zeros((n_samples, self.n_reservoir))])\n",
        "    outputs = np.vstack([lastoutput, np.zeros((n_samples, self.n_outputs))])\n",
        "\n",
        "    for n in range(n_samples): \n",
        "      states[n+1, :] = self.one_step(states[n, :], inputs[n+1, :], outputs[n, :])\n",
        "      outputs[n+1, :] = self.out_activation(matmul_gpu(self.W_out, np.concatenate([states[n+1, :], inputs[n+1, :]])))\n",
        "\n",
        "    #return self._unscale_teacher(self.out_activation(outputs[1,:]))\n",
        "\n",
        "    column_preds = self._unscale_teacher(self.out_activation(outputs[1:, :]))\n",
        "    preds = []\n",
        "\n",
        "    n_images = n_samples // self.n_inputs\n",
        "    for j in range(n_images) : \n",
        "      column_labels = np.argmax(column_preds[j*self.n_inputs : (j+1)*self.n_inputs], axis=1)\n",
        "      label = np.argmax(np.bincount(column_labels))\n",
        "      preds.append(label)\n",
        "    \n",
        "    return np.array(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGeSCmyKBF27"
      },
      "outputs": [],
      "source": [
        "c = make_default_context()\n",
        "dev = c.get_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqIoF9TdBF0O"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "esn = ESN(n_inputs = 28, n_outputs = 10, n_reservoir = 100,\n",
        "          alpha = 0.9, spectral_radius = 1.3, sparsity = 0.90, noise = 0.001, input_scaling=0.6)\n",
        "\n",
        "pred_train = esn.fit(U_train, V_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhaSz-vTBFyD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOFwsSoiFNzm"
      },
      "source": [
        "## Test the ESN without the reservoir (only the output layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kKLq8qMFNBX"
      },
      "outputs": [],
      "source": [
        "esn = ESN(img_size, Nx, Ny)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNhSoHV9FM_K"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "esn.compute_W_out(U_train.T, V_train.T, alpha=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvSYdIBryscf"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lr = LinearRegression(fit_intercept=False)\n",
        "lr.fit(U_train, V_train)\n",
        "print(lr.score(U_test, V_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85TIDUuR0sEz"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "lasso = Lasso(fit_intercept=False)\n",
        "lasso.fit(U_train, V_train)\n",
        "print(lasso.score(U_train, V_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7IdnTol5VNu"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge = Ridge(fit_intercept=False)\n",
        "ridge.fit(U_train, V_train)\n",
        "print(ridge.score(U_train, V_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiwIqCfuFM88"
      },
      "outputs": [],
      "source": [
        "# GridSearch\n",
        "%%time\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "clf = Ridge(fit_intercept=False)\n",
        "params = {\n",
        "    'alpha' : [0.9,0.95,0.99], \n",
        "    'max_iter' : [500, 1000, 5000, 10000],\n",
        "}\n",
        "\n",
        "gridsearch = GridSearchCV(clf, param_grid=params)\n",
        "\n",
        "gridsearch.fit(U_train, V_train)\n",
        "\n",
        "print(gridsearch.best_score_)\n",
        "print(gridsearch.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uaz2_6ddSEiJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnM0DXHKSJp3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cm9dXQHvSJmg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDYxv7mMSJkv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02Js4lIrSFCL"
      },
      "source": [
        "## GPU computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KuCkRr7_c39"
      },
      "outputs": [],
      "source": [
        "c = make_default_context()\n",
        "dev = c.get_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qUVQOuB8mZt"
      },
      "outputs": [],
      "source": [
        "matmul_gpu(2, 3, 4)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}